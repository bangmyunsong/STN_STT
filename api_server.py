"""
STN ê³ ê°ì„¼í„° STT ì‹œìŠ¤í…œ API ì„œë²„
FastAPI ê¸°ë°˜ REST API ì„œë²„ - ERP ì—°ë™ ë° STT ì²˜ë¦¬
"""

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import BaseModel, Field
from typing import Dict, List, Optional
import uuid
import json
import os
import tempfile
import whisper  # Render ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ê·¹í•œ ìµœì í™” ë²„ì „
from datetime import datetime, timedelta
import logging
import threading

# ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë ¨ import (ì„ íƒì )
try:
    from apscheduler.schedulers.background import BackgroundScheduler
    from apscheduler.triggers.cron import CronTrigger
    SCHEDULER_AVAILABLE = True
except ImportError:
    BackgroundScheduler = None
    CronTrigger = None
    SCHEDULER_AVAILABLE = False
    print("âš ï¸ APSchedulerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    print("âš ï¸ ì„¤ì¹˜í•˜ë ¤ë©´: pip install APScheduler>=3.10.0")

# ë¡œì»¬ ëª¨ë“ˆ import
from gpt_extractor import ERPExtractor, extract_erp_from_segments
from supabase_client import get_supabase_manager, save_stt_result, save_erp_result
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv('config.env')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="STN ê³ ê°ì„¼í„° STT ì‹œìŠ¤í…œ API",
    description="Whisper STT + GPT-3.5-turbo ê¸°ë°˜ ERP í•­ëª© ì¶”ì¶œ ë° ì—°ë™ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 422 ì˜¤ë¥˜ ë””ë²„ê¹…ì„ ìœ„í•œ ì˜ˆì™¸ í•¸ë“¤ëŸ¬
@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.error(f"422 ê²€ì¦ ì˜¤ë¥˜ ë°œìƒ - URL: {request.url}")
    logger.error(f"ìš”ì²­ ë©”ì†Œë“œ: {request.method}")
    logger.error(f"ìš”ì²­ í—¤ë”: {dict(request.headers)}")
    
    # ìš”ì²­ ë³¸ë¬¸ ë¡œê¹…
    try:
        body = await request.body()
        logger.error(f"ìš”ì²­ ë³¸ë¬¸: {body.decode('utf-8')}")
    except Exception as e:
        logger.error(f"ìš”ì²­ ë³¸ë¬¸ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ë¡œê¹…
    logger.error(f"ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°: {dict(request.query_params)}")
    
    # ìƒì„¸í•œ ê²€ì¦ ì˜¤ë¥˜ ë¡œê¹…
    logger.error(f"ê²€ì¦ ì˜¤ë¥˜ ìƒì„¸:")
    for error in exc.errors():
        logger.error(f"  - í•„ë“œ: {error.get('loc')}")
        logger.error(f"  - ì˜¤ë¥˜: {error.get('msg')}")
        logger.error(f"  - íƒ€ì…: {error.get('type')}")
        logger.error(f"  - ì…ë ¥ê°’: {error.get('input', 'N/A')}")
    
    return JSONResponse(
        status_code=422,
        content={
            "detail": exc.errors(),
            "message": "ìš”ì²­ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨",
            "debug_info": {
                "url": str(request.url),
                "method": request.method,
                "errors": exc.errors()
            }
        }
    )

# ì „ì—­ ë³€ìˆ˜
whisper_model = None
erp_extractor = None
supabase_manager = None

# ëª¨ë¸ ìºì‹±ìš© ë”•ì…”ë„ˆë¦¬ (ì„±ëŠ¥ ìµœì í™”)
cached_whisper_models = {}

def clear_model_cache():
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ëª¨ë¸ ìºì‹œ ì •ë¦¬ í•¨ìˆ˜"""
    global cached_whisper_models
    cached_whisper_models.clear()
    logger.info("ëª¨ë¸ ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

def clear_whisper_file_cache():
    """ì†ìƒëœ Whisper íŒŒì¼ ìºì‹œë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    import os
    import shutil
    from pathlib import Path
    
    try:
        # Windows í™˜ê²½ì—ì„œ Whisper ìºì‹œ ê²½ë¡œ
        cache_paths = [
            Path.home() / ".cache" / "whisper",  # Linux/Mac
            Path(os.getenv('LOCALAPPDATA', '')) / "whisper",  # Windows
            Path(os.getenv('APPDATA', '')) / "whisper",  # Windows ëŒ€ì•ˆ
        ]
        
        cleared_paths = []
        for cache_path in cache_paths:
            if cache_path.exists() and cache_path.is_dir():
                try:
                    shutil.rmtree(cache_path)
                    cleared_paths.append(str(cache_path))
                    logger.info(f"Whisper ìºì‹œ í´ë” ì‚­ì œë¨: {cache_path}")
                except Exception as e:
                    logger.warning(f"ìºì‹œ í´ë” ì‚­ì œ ì‹¤íŒ¨ ({cache_path}): {e}")
        
        if cleared_paths:
            logger.info(f"ì´ {len(cleared_paths)}ê°œì˜ ìºì‹œ í´ë”ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True, cleared_paths
        else:
            logger.info("ì •ë¦¬í•  Whisper ìºì‹œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False, []
            
    except Exception as e:
        logger.error(f"Whisper ìºì‹œ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return False, []

# ìƒìˆ˜ ì •ì˜
AUDIO_DIRECTORY = "src_record"  # ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬

# ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¥ì
SUPPORTED_AUDIO_EXTENSIONS = ['.mp3', '.wav', '.m4a', '.flac', '.aac', '.ogg']

# ì¼ìë³„ í´ë” ê´€ë¦¬ í•¨ìˆ˜
def create_daily_directory():
    """
    ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ src_record í•˜ìœ„ì— YYYY-MM-DD í˜•ì‹ì˜ í´ë” ìƒì„±
    """
    try:
        today = datetime.now().strftime('%Y-%m-%d')
        daily_path = os.path.join(AUDIO_DIRECTORY, today)
        
        # ê¸°ë³¸ src_record ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(AUDIO_DIRECTORY):
            os.makedirs(AUDIO_DIRECTORY)
            logger.info(f"ê¸°ë³¸ ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±: {AUDIO_DIRECTORY}")
        
        # ì˜¤ëŠ˜ ë‚ ì§œ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(daily_path):
            os.makedirs(daily_path)
            logger.info(f"ì¼ìë³„ í´ë” ìƒì„±: {daily_path}")
        else:
            logger.info(f"ì¼ìë³„ í´ë” ì´ë¯¸ ì¡´ì¬: {daily_path}")
            
        return daily_path
        
    except Exception as e:
        logger.error(f"ì¼ìë³„ í´ë” ìƒì„± ì‹¤íŒ¨: {e}")
        return None

# ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë ¨ ë³€ìˆ˜
scheduler = None

def create_daily_directory_with_date(target_date=None, auto_create=True):
    """
    íŠ¹ì • ë‚ ì§œì˜ í´ë”ë¥¼ ìƒì„± (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)
    
    Args:
        target_date: ìƒì„±í•  ë‚ ì§œ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
        auto_create: ìë™ ìƒì„± ì—¬ë¶€
    """
    try:
        if target_date is None:
            target_date = datetime.now()
        
        date_str = target_date.strftime('%Y-%m-%d')
        daily_path = os.path.join(AUDIO_DIRECTORY, date_str)
        
        # ê¸°ë³¸ src_record ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(AUDIO_DIRECTORY):
            os.makedirs(AUDIO_DIRECTORY)
            logger.info(f"ê¸°ë³¸ ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±: {AUDIO_DIRECTORY}")
        
        # í•´ë‹¹ ë‚ ì§œ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(daily_path):
            if auto_create:
                os.makedirs(daily_path)
                logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬: ì¼ìë³„ í´ë” ìƒì„± ì™„ë£Œ - {daily_path}")
            else:
                logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬: í´ë” ìƒì„± í•„ìš” - {daily_path} (auto_create=False)")
        else:
            logger.info(f"ìŠ¤ì¼€ì¤„ëŸ¬: ì¼ìë³„ í´ë” ì´ë¯¸ ì¡´ì¬ - {daily_path}")
            
        return daily_path
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬: ì¼ìë³„ í´ë” ìƒì„± ì‹¤íŒ¨ - {e}")
        return None

def ensure_today_folder_exists():
    """
    ì˜¤ëŠ˜ ë‚ ì§œ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
    """
    return create_daily_directory_with_date(datetime.now(), auto_create=True)

def scheduled_daily_folder_creation():
    """
    ë§¤ì¼ 0ì‹œì— ì‹¤í–‰ë˜ëŠ” ì¼ë³„ í´ë” ìƒì„± í•¨ìˆ˜
    """
    try:
        today = datetime.now()
        daily_path = create_daily_directory_with_date(today, auto_create=True)
        
        if daily_path:
            logger.info(f"âœ… ìŠ¤ì¼€ì¤„ëŸ¬: {today.strftime('%Y-%m-%d')} í´ë” ìƒì„± ì™„ë£Œ")
        else:
            logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬: {today.strftime('%Y-%m-%d')} í´ë” ìƒì„± ì‹¤íŒ¨")
            
    except Exception as e:
        logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

def get_daily_directory_path(date_str=None):
    """
    íŠ¹ì • ë‚ ì§œì˜ í´ë” ê²½ë¡œë¥¼ ë°˜í™˜ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
    
    Args:
        date_str (str): YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
    
    Returns:
        str: ì¼ìë³„ í´ë” ê²½ë¡œ
    """
    if date_str is None:
        date_str = datetime.now().strftime('%Y-%m-%d')
    
    return os.path.join(AUDIO_DIRECTORY, date_str)

# Pydantic ëª¨ë¸ë“¤
class ERPData(BaseModel):
    """ERP ë“±ë¡ ë°ì´í„° ëª¨ë¸"""
    as_support: str = Field("", alias="AS ë° ì§€ì›", description="ì§€ì› ë°©ì‹ (ë°©ë¬¸ê¸°ìˆ ì§€ì›, ì›ê²©ê¸°ìˆ ì§€ì› ë“±)")
    request_org: str = Field("", alias="ìš”ì²­ê¸°ê´€", description="ê³ ê°ì‚¬ ë˜ëŠ” ê¸°ê´€ëª…")
    work_location: str = Field("", alias="ì‘ì—…êµ­ì†Œ", description="ì§€ì—­ ë˜ëŠ” ìœ„ì¹˜")
    request_date: str = Field("", alias="ìš”ì²­ì¼", description="ê³ ê°ì´ ìš”ì²­í•œ ë‚ ì§œ (YYYY-MM-DD)")
    request_time: str = Field("", alias="ìš”ì²­ì‹œê°„", description="ê³ ê°ì´ ìš”ì²­í•œ ì‹œê°„ (24ì‹œê°„ í˜•ì‹)")
    requester: str = Field("", alias="ìš”ì²­ì", description="ê³ ê° ë‹´ë‹¹ì ì´ë¦„")
    support_count: str = Field("", alias="ì§€ì›ì¸ì›ìˆ˜", description="í•„ìš”í•œ ì§€ì› ì¸ì› ìˆ˜")
    support_staff: str = Field("", alias="ì§€ì›ìš”ì›", description="íˆ¬ì… ì˜ˆì • ê¸°ìˆ ì ì´ë¦„")
    equipment_name: str = Field("", alias="ì¥ë¹„ëª…", description="ì¥ë¹„ ì¢…ë¥˜")
    model_name: str = Field("", alias="ê¸°ì¢…ëª…", description="êµ¬ì²´ì ì¸ ì¥ë¹„ ëª¨ë¸ëª…")
    as_period_status: str = Field("", alias="A/Sê¸°ê°„ë§Œë£Œì—¬ë¶€", description="A/S ê¸°ê°„ ìƒíƒœ (ë¬´ìƒ, ìœ ìƒ)")
    system_name: str = Field("", alias="ì‹œìŠ¤í…œëª…(ê³ ê°ì‚¬ëª…)", description="ê³ ê°ì‚¬ ì‹œìŠ¤í…œëª…")
    request_content: str = Field("", alias="ìš”ì²­ ì‚¬í•­", description="ê³ ê° ìš”ì²­ ë‚´ìš© ìš”ì•½")
    
    class Config:
        allow_population_by_field_name = True
        schema_extra = {
            "example": {
                "AS ë° ì§€ì›": "ì›ê²©ê¸°ìˆ ì§€ì›",
                "ìš”ì²­ê¸°ê´€": "ìˆ˜ìì›ê³µì‚¬ FAë§",
                "ì‘ì—…êµ­ì†Œ": "ëŒ€ì „",
                "ìš”ì²­ì¼": "2025-04-18",
                "ìš”ì²­ì‹œê°„": "15",
                "ìš”ì²­ì": "ì´ì •ìˆœ",
                "ì§€ì›ì¸ì›ìˆ˜": "1ëª…",
                "ì§€ì›ìš”ì›": "ì„ì„ ë¬µ",
                "ì¥ë¹„ëª…": "MSPP",
                "ê¸°ì¢…ëª…": "1646SMC",
                "A/Sê¸°ê°„ë§Œë£Œì—¬ë¶€": "ìœ ìƒ",
                "ì‹œìŠ¤í…œëª…(ê³ ê°ì‚¬ëª…)": "ìˆ˜ìì›ê³µì‚¬ FAë§",
                "ìš”ì²­ ì‚¬í•­": "ìˆ˜ìì› íšŒì„  ë¬¸ì˜ê±´"
            }
        }

class ERPRegisterResponse(BaseModel):
    """ERP ë“±ë¡ ì‘ë‹µ ëª¨ë¸"""
    status: str = Field(..., description="ì²˜ë¦¬ ìƒíƒœ")
    erp_id: str = Field(..., description="ERP ë“±ë¡ ID")
    message: Optional[str] = Field(None, description="ì²˜ë¦¬ ë©”ì‹œì§€")

class STTRequest(BaseModel):
    """STT ì²˜ë¦¬ ìš”ì²­ ëª¨ë¸"""
    model_name: Optional[str] = Field("tiny", description="Whisper ëª¨ë¸ëª…")
    language: Optional[str] = Field(None, description="ì–¸ì–´ ì½”ë“œ")
    enable_diarization: Optional[bool] = Field(True, description="í™”ì ë¶„ë¦¬ í™œì„±í™”")

class STTResponse(BaseModel):
    """STT ì²˜ë¦¬ ì‘ë‹µ ëª¨ë¸"""
    status: str = Field(..., description="ì²˜ë¦¬ ìƒíƒœ")
    transcript: str = Field(..., description="ì „ì²´ í…ìŠ¤íŠ¸")
    segments: List[Dict] = Field(..., description="ì„¸ê·¸ë¨¼íŠ¸ë³„ ê²°ê³¼")
    erp_data: Optional[ERPData] = Field(None, description="ì¶”ì¶œëœ ERP ë°ì´í„°")
    processing_time: float = Field(..., description="ì²˜ë¦¬ ì‹œê°„(ì´ˆ)")
    file_id: str = Field(..., description="íŒŒì¼ ì²˜ë¦¬ ID")
    session_id: Optional[int] = Field(None, description="ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ID")
    extraction_id: Optional[int] = Field(None, description="ERP ì¶”ì¶œ ê²°ê³¼ ID")

# ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
def initialize_models():
    """ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ (ì•ˆì „í•œ ë‹¨ê³„ë³„ ì´ˆê¸°í™”)"""
    global whisper_model, erp_extractor, supabase_manager
    
    logger.info("ğŸš€ ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")

    # Render 512MB ê·¹í•œ ë©”ëª¨ë¦¬ ìµœì í™” ëª¨ë“œ
    import os
    import gc
    import psutil
    
    # ê·¹í•œ ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
    os.environ["OMP_NUM_THREADS"] = "1"
    os.environ["MKL_NUM_THREADS"] = "1"
    os.environ["NUMEXPR_NUM_THREADS"] = "1"
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    os.environ["PYTORCH_JIT"] = "0"
    os.environ["CUDA_VISIBLE_DEVICES"] = ""
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:128"
    
    # ë©”ëª¨ë¦¬ ìƒíƒœ ì²´í¬ í•¨ìˆ˜
    def log_memory(stage="Unknown"):
        try:
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            logger.info(f"ğŸ§  [{stage}] ë©”ëª¨ë¦¬: {memory_mb:.1f}MB / 512MB")
            if memory_mb > 400:
                logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ìœ„í—˜ ìˆ˜ì¤€: {memory_mb:.1f}MB")
                gc.collect()
            return memory_mb
        except Exception as e:
            logger.warning(f"ë©”ëª¨ë¦¬ ì²´í¬ ì‹¤íŒ¨: {e}")
            return 0
    
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
    gc.collect()
    log_memory("ì´ˆê¸°í™” ì‹œì‘")
    
    logger.info("ğŸ’¾ ê·¹í•œ ë©”ëª¨ë¦¬ ìµœì í™” ëª¨ë“œ (Whisper tiny ëª¨ë¸)")
    
    # 1. Whisper tiny ëª¨ë¸ ë¡œë“œ (ê·¹í•œ ìµœì í™”)
    try:
        logger.info("1ï¸âƒ£ Whisper tiny ëª¨ë¸ ë¡œë”© ì¤‘... (ë©”ëª¨ë¦¬ ìµœì í™”)")
        
        # ëª¨ë¸ ë¡œë”© ì „ ë©”ëª¨ë¦¬ ì²´í¬
        log_memory("ëª¨ë¸ ë¡œë”© ì „")
        
        # tiny ëª¨ë¸ë§Œ ë¡œë“œ (39MB) - ê°€ì¥ ì‘ì€ ëª¨ë¸
        model_size = os.getenv("STT_MODEL", "tiny")
        logger.info(f"ğŸ”§ í™˜ê²½ë³€ìˆ˜ STT_MODEL: {model_size}")
        
        # tinyë¡œ ê°•ì œ ì„¤ì • (ë©”ëª¨ë¦¬ ì ˆì•½)
        if model_size != "tiny":
            logger.warning(f"âš ï¸ Render 512MB ì œí•œìœ¼ë¡œ ì¸í•´ {model_size} â†’ tinyë¡œ ë³€ê²½")
            model_size = "tiny"
        
        whisper_model = whisper.load_model(model_size)
        logger.info("âœ… Whisper tiny ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # ëª¨ë¸ ë¡œë”© í›„ ë©”ëª¨ë¦¬ ì²´í¬
        log_memory("ëª¨ë¸ ë¡œë”© í›„")
        
        # ìºì‹œì— ì €ì¥
        cached_whisper_models[model_size] = whisper_model
        
    except Exception as e:
        logger.error(f"âŒ Whisper ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise
    
    # 2. ERP Extractor ì´ˆê¸°í™” (ì„ íƒì )
    try:
        logger.info("2ï¸âƒ£ ERP Extractor ì´ˆê¸°í™” ì¤‘...")
        erp_extractor = ERPExtractor()
        logger.info("âœ… ERP Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ ERP Extractor ì´ˆê¸°í™” ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        logger.warning("ğŸ’¡ í•´ê²°ë°©ë²•: config.envì—ì„œ OPENAI_API_KEY í™•ì¸")
        erp_extractor = None
    
    # 3. Supabase ë§¤ë‹ˆì € ì´ˆê¸°í™” (ì„ íƒì )
    try:
        logger.info("3ï¸âƒ£ Supabase ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
        supabase_manager = get_supabase_manager()
        logger.info("âœ… Supabase ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"âš ï¸ Supabase ì´ˆê¸°í™” ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        logger.warning("ğŸ’¡ í•´ê²°ë°©ë²•: config.envì—ì„œ Supabase ì„¤ì • í™•ì¸")
        supabase_manager = None
    
    logger.info("ğŸ‰ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!")

# ì˜ì¡´ì„± í•¨ìˆ˜
def get_whisper_model():
    """Whisper ëª¨ë¸ ì˜ì¡´ì„± (ê·¹í•œ ë©”ëª¨ë¦¬ ìµœì í™”)"""
    if whisper_model is None:
        raise HTTPException(status_code=500, detail="Whisper ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    return whisper_model

def get_erp_extractor():
    """ERP Extractor ì˜ì¡´ì„± (ì„ íƒì )"""
    if erp_extractor is None:
        logger.warning("ERP Extractorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ERP ì¶”ì¶œ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        # ê¸°ë³¸ ê°ì²´ ë°˜í™˜ ë˜ëŠ” None ë°˜í™˜í•˜ì—¬ ì²˜ë¦¬ ë¡œì§ì—ì„œ í™•ì¸í•˜ê²Œ í•¨
        return None
    return erp_extractor

def get_supabase_manager_dep():
    """Supabase ë§¤ë‹ˆì € ì˜ì¡´ì„± (ì„ íƒì‚¬í•­)"""
    return supabase_manager  # Noneì¼ ìˆ˜ ìˆìŒ

# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/")
async def root():
    """API ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "message": "STN ê³ ê°ì„¼í„° STT ì‹œìŠ¤í…œ API ì„œë²„",
        "version": "1.0.0",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    supabase_status = False
    if supabase_manager:
        try:
            supabase_status = supabase_manager.health_check()
        except:
            supabase_status = False
    
    scheduler_status = False
    if SCHEDULER_AVAILABLE and scheduler:
        try:
            scheduler_status = scheduler.running
        except:
            scheduler_status = False
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "models": {
            "whisper": whisper_model is not None,
            "erp_extractor": erp_extractor is not None,
            "supabase": supabase_status
        },
        "scheduler": {
            "available": SCHEDULER_AVAILABLE,
            "running": scheduler_status
        }
    }

@app.get("/test")
async def test_endpoint():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "ok",
        "message": "API ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/erp-sample-register", response_model=ERPRegisterResponse)
async def register_erp_sample(
    erp_data: ERPData, 
    extraction_id: Optional[int] = None,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    ERP ì—°ë™ìš© ìƒ˜í”Œ ë“±ë¡ API
    PRD ìš”êµ¬ì‚¬í•­ì— ë”°ë¥¸ í…ŒìŠ¤íŠ¸ìš© ì¸í„°í˜ì´ìŠ¤
    """
    try:
        # Mock ERP ID ìƒì„±
        erp_id = f"mock{uuid.uuid4().hex[:8]}"
        
        logger.info(f"ERP ìƒ˜í”Œ ë“±ë¡ ìš”ì²­ - ID: {erp_id}")
        logger.info(f"ë“±ë¡ ë°ì´í„°: {erp_data.dict()}")
        
        # ì‹¤ì œ ERP ì‹œìŠ¤í…œ ì—°ë™ ì‹œë®¬ë ˆì´ì…˜ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ì„±ê³µ ì‘ë‹µ)
        response_data = {
            "status": "success",
            "erp_id": erp_id,
            "message": "ERP ì‹œìŠ¤í…œì— ì •ìƒì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
        # Supabaseì— ë“±ë¡ ë¡œê·¸ ì €ì¥
        if extraction_id and supabase_mgr:
            try:
                supabase_mgr.save_erp_register_log(
                    extraction_id=extraction_id,
                    erp_id=erp_id,
                    status="success",
                    response_data=response_data
                )
                logger.info(f"ERP ë“±ë¡ ë¡œê·¸ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
            except Exception as e:
                logger.warning(f"ERP ë“±ë¡ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        response = ERPRegisterResponse(**response_data)
        return response
        
    except Exception as e:
        logger.error(f"ERP ë“±ë¡ ì‹¤íŒ¨: {e}")
        
        # ì‹¤íŒ¨ ë¡œê·¸ë„ ì €ì¥
        if extraction_id and supabase_mgr:
            try:
                supabase_mgr.save_erp_register_log(
                    extraction_id=extraction_id,
                    erp_id="",
                    status="failed",
                    response_data={"error": str(e)}
                )
            except:
                pass
        
        raise HTTPException(status_code=500, detail=f"ERP ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/stt-process", response_model=STTResponse)
async def process_audio_file(
    file: UploadFile = File(..., description="ì—…ë¡œë“œí•  ìŒì„± íŒŒì¼"),
    model_name: str = "tiny",
    language: Optional[str] = None,
    enable_diarization: bool = True,
    extract_erp: bool = True,
    save_to_db: bool = True,
    whisper_model=Depends(get_whisper_model),
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    ìŒì„± íŒŒì¼ STT ì²˜ë¦¬ ë° ERP í•­ëª© ì¶”ì¶œ API
    """
    start_time = datetime.now()
    file_id = f"stt_{uuid.uuid4().hex[:8]}"
    
    try:
        logger.info(f"STT ì²˜ë¦¬ ì‹œì‘ - File ID: {file_id}, íŒŒì¼ëª…: {file.filename}")
        
        # íŒŒì¼ í˜•ì‹ ê²€ì¦
        allowed_extensions = ['.mp3', '.wav', '.m4a', '.flac']
        file_extension = os.path.splitext(file.filename)[1].lower()
        
        if file_extension not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(allowed_extensions)}"
            )
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            # Whisper tiny ëª¨ë¸ STT ì²˜ë¦¬ (ê·¹í•œ ë©”ëª¨ë¦¬ ìµœì í™”)
            logger.info(f"Whisper STT ì²˜ë¦¬ ì¤‘ - ëª¨ë¸: tiny (ë©”ëª¨ë¦¬ ìµœì í™”)")
            
            try:
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
                import psutil
                import gc
                
                def check_memory():
                    try:
                        process = psutil.Process()
                        memory_mb = process.memory_info().rss / 1024 / 1024
                        logger.info(f"ğŸ§  STT ì²˜ë¦¬ ì¤‘ ë©”ëª¨ë¦¬: {memory_mb:.1f}MB")
                        if memory_mb > 450:
                            logger.warning("âš ï¸ ë©”ëª¨ë¦¬ ì„ê³„ì  ê·¼ì ‘, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰")
                            gc.collect()
                        return memory_mb
                    except:
                        return 0
                
                check_memory()
                
                # tiny ëª¨ë¸ ê°•ì œ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
                current_model = whisper_model
                if current_model is None:
                    raise HTTPException(status_code=500, detail="Whisper ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
                logger.info(f"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼: {temp_file_path}")
                
                # STT ì‹¤í–‰ (ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜)
                result = current_model.transcribe(
                    temp_file_path,
                    language=language,
                    verbose=False,  # ë©”ëª¨ë¦¬ ì ˆì•½
                    fp16=False,  # CPUì—ì„œëŠ” fp16 ë¹„í™œì„±í™”
                )
                
                logger.info("âœ… Whisper STT ì²˜ë¦¬ ì™„ë£Œ")
                check_memory()
                
            except Exception as stt_error:
                logger.error(f"âŒ Whisper STT ì²˜ë¦¬ ì‹¤íŒ¨: {stt_error}")
                raise HTTPException(
                    status_code=500, 
                    detail=f"ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(stt_error)}"
                )
            
            # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì²˜ë¦¬
            segments = []
            for i, segment in enumerate(result.get("segments", [])):
                segment_data = {
                    "id": i,
                    "text": segment["text"].strip(),
                    "start": segment["start"],
                    "end": segment["end"],
                    "speaker": f"Speaker_{i % 2}"  # ê°„ë‹¨í•œ í™”ì ë¶„ë¦¬ ì‹œë®¬ë ˆì´ì…˜
                }
                segments.append(segment_data)
            
            # ERP ë°ì´í„° ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ê°œì„ )
            erp_data = None
            if extract_erp and segments and erp_extractor is not None:
                try:
                    logger.info("ERP ë°ì´í„° ì¶”ì¶œ ì¤‘... (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                    erp_dict = erp_extractor.extract_from_segments(segments)
                    erp_data = ERPData(**erp_dict)
                    logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
                except TimeoutError as e:
                    logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ: {e}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
                except Exception as e:
                    logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            elif extract_erp and erp_extractor is None:
                logger.info("âš ï¸ ERP Extractorê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # Supabaseì— ê²°ê³¼ ì €ì¥ (ì˜µì…˜)
            session_id = None
            extraction_id = None
            
            if save_to_db and supabase_mgr:
                try:
                    logger.info("Supabaseì— STT ê²°ê³¼ ì €ì¥ ì¤‘...")
                    
                    # STT ì„¸ì…˜ ìƒì„± ë° ì—…ë°ì´íŠ¸
                    session = supabase_mgr.create_stt_session(
                        file_name=file.filename,
                        file_id=file_id,
                        model_name=model_name,
                        language=language
                    )
                    session_id = session['id']
                    
                    # STT ê²°ê³¼ ì—…ë°ì´íŠ¸
                    supabase_mgr.update_stt_session(
                        session_id=session_id,
                        transcript=result["text"],
                        segments=segments,
                        processing_time=processing_time,
                        status="completed"
                    )
                    
                    # ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥
                    if erp_data:
                        erp_dict = erp_data.dict(by_alias=True)
                        extraction = supabase_mgr.save_erp_extraction(
                            session_id=session_id,
                            erp_data=erp_dict
                        )
                        extraction_id = extraction['id']
                        logger.info(f"ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
                        
                        # ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ (DB ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°)
                        try:
                            logger.info("ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ ì¤‘...")
                            
                            # Mock ERP ID ìƒì„±
                            erp_id = f"auto{uuid.uuid4().hex[:8]}"
                            
                            # ERP ë“±ë¡ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ERP ì‹œìŠ¤í…œ ì—°ë™ ì‹œ ì´ ë¶€ë¶„ì„ ìˆ˜ì •)
                            erp_response_data = {
                                "status": "success",
                                "erp_id": erp_id,
                                "message": "STT ì²˜ë¦¬ ì¤‘ ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
                            }
                            
                            # ERP ë“±ë¡ ë¡œê·¸ ì €ì¥
                            supabase_mgr.save_erp_register_log(
                                extraction_id=extraction_id,
                                erp_id=erp_id,
                                status="success",
                                response_data=erp_response_data
                            )
                            
                            logger.info(f"ERP ìë™ ë“±ë¡ ì™„ë£Œ - ERP ID: {erp_id}, ì¶”ì¶œ ID: {extraction_id}")
                            
                        except Exception as e:
                            logger.warning(f"ERP ìë™ ë“±ë¡ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                            # ì‹¤íŒ¨ ë¡œê·¸ë„ ì €ì¥
                            try:
                                supabase_mgr.save_erp_register_log(
                                    extraction_id=extraction_id,
                                    erp_id="",
                                    status="failed",
                                    response_data={"error": str(e)}
                                )
                            except:
                                pass
                    
                    logger.info(f"Supabase ì €ì¥ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}")
                    
                except Exception as e:
                    logger.warning(f"Supabase ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            
            # ì‘ë‹µ ìƒì„±
            response = STTResponse(
                status="success",
                transcript=result["text"],
                segments=segments,
                erp_data=erp_data,
                processing_time=processing_time,
                file_id=file_id
            )
            
            # ì‘ë‹µì— DB ì €ì¥ ì •ë³´ ì¶”ê°€ (ë™ì  í•„ë“œ)
            if session_id:
                response.session_id = session_id
            if extraction_id:
                response.extraction_id = extraction_id
            
            logger.info(f"STT ì²˜ë¦¬ ì™„ë£Œ - File ID: {file_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            return response
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"STT ì²˜ë¦¬ ì‹¤íŒ¨ - File ID: {file_id}: {e}")
        raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/stt-process-file", response_model=STTResponse)
async def process_audio_file_from_directory(
    filename: str,
    model_name: str = "tiny",
    language: Optional[str] = None,
    enable_diarization: bool = True,
    extract_erp: bool = True,
    save_to_db: bool = True,
    whisper_model=Depends(get_whisper_model),
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    src_record ë””ë ‰í† ë¦¬ì˜ ìŒì„± íŒŒì¼ STT ì²˜ë¦¬ ë° ERP í•­ëª© ì¶”ì¶œ API
    """
    start_time = datetime.now()
    file_id = f"stt_{uuid.uuid4().hex[:8]}"
    
    try:
        # íŒŒì¼ ê²½ë¡œ ê²€ì¦ (ì¼ìë³„ í´ë” êµ¬ì¡° ì§€ì›)
        # filenameì´ "ë‚ ì§œí´ë”/íŒŒì¼ëª…" í˜•ì‹ì´ê±°ë‚˜ ë‹¨ìˆœíˆ "íŒŒì¼ëª…"ì¼ ìˆ˜ ìˆìŒ
        file_path = os.path.join(AUDIO_DIRECTORY, filename)
        
        # Windows ê²½ë¡œ ì •ê·œí™”
        file_path = os.path.normpath(file_path)
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (Whisperê°€ ìƒëŒ€ ê²½ë¡œì—ì„œ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŒ)
        file_path = os.path.abspath(file_path)
        
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - ìš”ì²­ëœ íŒŒì¼ëª…: {filename}")
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - êµ¬ì„±ëœ ê²½ë¡œ: {file_path}")
        logger.info(f"íŒŒì¼ ê²½ë¡œ í™•ì¸ - íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(file_path)}")
        
        if not os.path.exists(file_path):
            raise HTTPException(
                status_code=404, 
                detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename} (ê²½ë¡œ: {file_path})"
            )
        
        if not os.path.isfile(file_path):
            raise HTTPException(
                status_code=400, 
                detail=f"ìœ íš¨í•œ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {filename} (ê²½ë¡œ: {file_path})"
            )
        
        # íŒŒì¼ í˜•ì‹ ê²€ì¦ (ì‹¤ì œ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì¶”ì¶œ)
        actual_filename = os.path.basename(filename)  # ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
        file_extension = os.path.splitext(actual_filename)[1].lower()
        
        if file_extension not in SUPPORTED_AUDIO_EXTENSIONS:
            raise HTTPException(
                status_code=400, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_AUDIO_EXTENSIONS)}"
            )
        
        logger.info(f"STT ì²˜ë¦¬ ì‹œì‘ - File ID: {file_id}, íŒŒì¼ê²½ë¡œ: {file_path}")
        
        # Whisper tiny ëª¨ë¸ STT ì²˜ë¦¬ (ê·¹í•œ ë©”ëª¨ë¦¬ ìµœì í™”)
        logger.info(f"Whisper STT ì²˜ë¦¬ ì¤‘ - ëª¨ë¸: tiny (ë©”ëª¨ë¦¬ ìµœì í™”)")
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”: tiny ëª¨ë¸ë§Œ ê°•ì œ ì‚¬ìš©
            if model_name != "tiny":
                logger.warning(f"âš ï¸ Render 512MB ì œí•œìœ¼ë¡œ ì¸í•´ {model_name} â†’ tinyë¡œ ë³€ê²½")
                model_name = "tiny"
            
            # ê¸°ë³¸ tiny ëª¨ë¸ ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
            current_model = whisper_model
            if current_model is None:
                raise HTTPException(status_code=500, detail="Whisper ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            logger.info("âœ… Whisper tiny ëª¨ë¸ ì‚¬ìš© (ë©”ëª¨ë¦¬ ìµœì í™”)")
        
            # STT ì‹¤í–‰ (ë©”ëª¨ë¦¬ ìµœì í™”)
            logger.info(f"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼: {file_path}")
            logger.info(f"ğŸŒ ì–¸ì–´ ì„¤ì •: {language}")
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            import psutil
            import gc
            
            def check_memory():
                try:
                    process = psutil.Process()
                    memory_mb = process.memory_info().rss / 1024 / 1024
                    logger.info(f"ğŸ§  STT ì²˜ë¦¬ ì¤‘ ë©”ëª¨ë¦¬: {memory_mb:.1f}MB")
                    if memory_mb > 450:
                        logger.warning("âš ï¸ ë©”ëª¨ë¦¬ ì„ê³„ì  ê·¼ì ‘, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰")
                        gc.collect()
                    return memory_mb
                except:
                    return 0
            
            check_memory()
            
            # STT ì‹¤í–‰ (ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜)
            result = current_model.transcribe(
                file_path,
                language=language,
                verbose=False,  # ë©”ëª¨ë¦¬ ì ˆì•½
                fp16=False,  # CPUì—ì„œëŠ” fp16 ë¹„í™œì„±í™”
            )
            
            logger.info(f"âœ… Whisper transcribe ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(result.get('text', ''))}")
            check_memory()
            
        except Exception as transcribe_error:
            logger.error(f"âŒ Whisper transcribe ì‹¤íŒ¨ - íŒŒì¼: {file_path}")
            logger.error(f"âŒ ì˜¤ë¥˜ ë‚´ìš©: {transcribe_error}")
            
            # FFmpeg ê´€ë ¨ ì˜¤ë¥˜ ê°ì§€
            error_msg = str(transcribe_error)
            if "WinError 2" in error_msg or "CreateProcess" in error_msg:
                raise HTTPException(
                    status_code=500,
                    detail="FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. WhisperëŠ” ì˜¤ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )
            else:
                raise HTTPException(
                    status_code=500,
                    detail=f"ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(transcribe_error)}"
                )
        
        # ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ì²˜ë¦¬
        segments = []
        for i, segment in enumerate(result.get("segments", [])):
            segment_data = {
                "id": i,
                "text": segment["text"].strip(),
                "start": segment["start"],
                "end": segment["end"],
                "speaker": f"Speaker_{i % 2}"  # ê°„ë‹¨í•œ í™”ì ë¶„ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            }
            segments.append(segment_data)
        
        # ERP ë°ì´í„° ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ê°œì„ )
        erp_data = None
        if extract_erp and segments and erp_extractor is not None:
            try:
                logger.info("ERP ë°ì´í„° ì¶”ì¶œ ì¤‘... (30ì´ˆ íƒ€ì„ì•„ì›ƒ)")
                erp_dict = erp_extractor.extract_from_segments(segments)
                erp_data = ERPData(**erp_dict)
                logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
            except TimeoutError as e:
                logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ íƒ€ì„ì•„ì›ƒ: {e}")
                logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
            except Exception as e:
                logger.warning(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                logger.info("ERP ì¶”ì¶œì„ ê±´ë„ˆë›°ê³  STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        elif extract_erp and erp_extractor is None:
            logger.info("âš ï¸ ERP Extractorê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. STT ê²°ê³¼ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # Supabaseì— ê²°ê³¼ ì €ì¥ (ì˜µì…˜)
        session_id = None
        extraction_id = None
        
        if save_to_db and supabase_mgr:
            try:
                logger.info("Supabaseì— STT ê²°ê³¼ ì €ì¥ ì¤‘...")
                
                # STT ì„¸ì…˜ ìƒì„± ë° ì—…ë°ì´íŠ¸
                session = supabase_mgr.create_stt_session(
                    file_name=filename,
                    file_id=file_id,
                    model_name=model_name,
                    language=language
                )
                session_id = session['id']
                
                # STT ê²°ê³¼ ì—…ë°ì´íŠ¸
                supabase_mgr.update_stt_session(
                    session_id=session_id,
                    transcript=result["text"],
                    segments=segments,
                    processing_time=processing_time,
                    status="completed"
                )
                
                # ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥
                if erp_data:
                    erp_dict = erp_data.dict(by_alias=True)
                    extraction = supabase_mgr.save_erp_extraction(
                        session_id=session_id,
                        erp_data=erp_dict
                    )
                    extraction_id = extraction['id']
                    logger.info(f"ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ - ì¶”ì¶œ ID: {extraction_id}")
                    
                    # ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ (DB ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ëœ ê²½ìš°)
                    try:
                        logger.info("ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ ì¤‘...")
                        
                        # Mock ERP ID ìƒì„±
                        erp_id = f"auto{uuid.uuid4().hex[:8]}"
                        
                        # ERP ë“±ë¡ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ERP ì‹œìŠ¤í…œ ì—°ë™ ì‹œ ì´ ë¶€ë¶„ì„ ìˆ˜ì •)
                        erp_response_data = {
                            "status": "success",
                            "erp_id": erp_id,
                            "message": "STT ì²˜ë¦¬ ì¤‘ ERP ì‹œìŠ¤í…œì— ìë™ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤"
                        }
                        
                        # ERP ë“±ë¡ ë¡œê·¸ ì €ì¥
                        supabase_mgr.save_erp_register_log(
                            extraction_id=extraction_id,
                            erp_id=erp_id,
                            status="success",
                            response_data=erp_response_data
                        )
                        
                        logger.info(f"ERP ìë™ ë“±ë¡ ì™„ë£Œ - ERP ID: {erp_id}, ì¶”ì¶œ ID: {extraction_id}")
                        
                    except Exception as e:
                        logger.warning(f"ERP ìë™ ë“±ë¡ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
                        # ì‹¤íŒ¨ ë¡œê·¸ë„ ì €ì¥
                        try:
                            supabase_mgr.save_erp_register_log(
                                extraction_id=extraction_id,
                                erp_id="",
                                status="failed",
                                response_data={"error": str(e)}
                            )
                        except:
                            pass
                
                logger.info(f"Supabase ì €ì¥ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}")
                
            except Exception as e:
                logger.warning(f"Supabase ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        
        # ì‘ë‹µ ìƒì„±
        response = STTResponse(
            status="success",
            transcript=result["text"],
            segments=segments,
            erp_data=erp_data,
            processing_time=processing_time,
            file_id=file_id
        )
        
        # ì‘ë‹µì— DB ì €ì¥ ì •ë³´ ì¶”ê°€ (ë™ì  í•„ë“œ)
        if session_id:
            response.session_id = session_id
        if extraction_id:
            response.extraction_id = extraction_id
        
        logger.info(f"STT ì²˜ë¦¬ ì™„ë£Œ - File ID: {file_id}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"STT ì²˜ë¦¬ ì‹¤íŒ¨ - File ID: {file_id}: {e}")
        raise HTTPException(status_code=500, detail=f"STT ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/extract-erp")
async def extract_erp_from_text(
    conversation_text: str,
    erp_extractor=Depends(get_erp_extractor)
):
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ERP í•­ëª©ì„ ì¶”ì¶œí•˜ëŠ” API
    """
    try:
        logger.info("í…ìŠ¤íŠ¸ì—ì„œ ERP ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        erp_dict = erp_extractor.extract_erp_data(conversation_text)
        erp_data = ERPData(**erp_dict)
        
        return {
            "status": "success",
            "erp_data": erp_data,
            "message": "ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ"
        }
        
    except Exception as e:
        logger.error(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ERP ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ë°ì´í„° ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/api/sessions")
async def get_stt_sessions(
    limit: int = 50, 
    offset: int = 0,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """STT ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        sessions = supabase_mgr.get_stt_sessions(limit=limit, offset=offset)
        return {
            "status": "success",
            "sessions": sessions,
            "total": len(sessions)
        }
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/sessions/{session_id}")
async def get_stt_session(
    session_id: int,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """íŠ¹ì • STT ì„¸ì…˜ ìƒì„¸ ì¡°íšŒ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        session = supabase_mgr.get_stt_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ERP ì¶”ì¶œ ê²°ê³¼ë„ í•¨ê»˜ ì¡°íšŒ
        erp_extraction = supabase_mgr.get_erp_extraction(session_id)
        
        return {
            "status": "success",
            "session": session,
            "erp_extraction": erp_extraction
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì„¸ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/sessions/{session_id}/extract-erp")
async def extract_erp_for_session(
    session_id: int,
    erp_extractor=Depends(get_erp_extractor),
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """ê¸°ì¡´ STT ì„¸ì…˜ì— ëŒ€í•œ ERP ì¬ì¶”ì¶œ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        logger.info(f"ì„¸ì…˜ {session_id}ì— ëŒ€í•œ ERP ì¬ì¶”ì¶œ ì‹œì‘")
        
        # ì„¸ì…˜ ì •ë³´ ì¡°íšŒ
        session = supabase_mgr.get_stt_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # transcript ë˜ëŠ” segments í™•ì¸
        transcript = session.get('transcript')
        segments = session.get('segments')
        
        if not transcript and not segments:
            raise HTTPException(status_code=400, detail="ì„¸ì…˜ì— í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ERP ë°ì´í„° ì¶”ì¶œ
        erp_data = None
        try:
            if segments:
                # ì„¸ê·¸ë¨¼íŠ¸ê°€ ìˆìœ¼ë©´ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì¶”ì¶œ
                logger.info("ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ERP ë°ì´í„° ì¶”ì¶œ ì¤‘...")
                
                # segmentsê°€ ë¬¸ìì—´ì¸ ê²½ìš° JSONìœ¼ë¡œ íŒŒì‹±
                if isinstance(segments, str):
                    try:
                        segments = json.loads(segments)
                        logger.info("ì„¸ê·¸ë¨¼íŠ¸ JSON íŒŒì‹± ì™„ë£Œ")
                    except json.JSONDecodeError as e:
                        logger.warning(f"ì„¸ê·¸ë¨¼íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
                        segments = None
                
                if segments and isinstance(segments, list):
                    erp_dict = erp_extractor.extract_from_segments(segments)
                else:
                    logger.info("ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                    erp_dict = erp_extractor.extract_erp_data(transcript)
            else:
                # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
                logger.info("ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ERP ë°ì´í„° ì¶”ì¶œ ì¤‘...")
                erp_dict = erp_extractor.extract_erp_data(transcript)
            
            erp_data = ERPData(**erp_dict)
            logger.info(f"ERP ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {erp_dict}")
            
        except Exception as e:
            logger.error(f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=f"ERP ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        
        # ê¸°ì¡´ ERP ì¶”ì¶œ ê²°ê³¼ í™•ì¸
        existing_extraction = supabase_mgr.get_erp_extraction(session_id)
        
        extraction_id = None
        if existing_extraction:
            # ê¸°ì¡´ ì¶”ì¶œ ê²°ê³¼ ì—…ë°ì´íŠ¸
            logger.info(f"ê¸°ì¡´ ERP ì¶”ì¶œ ê²°ê³¼ ì—…ë°ì´íŠ¸ - ì¶”ì¶œ ID: {existing_extraction['id']}")
            updated_extraction = supabase_mgr.update_erp_extraction(
                extraction_id=existing_extraction['id'],
                erp_data=erp_data.dict(by_alias=True)
            )
            extraction_id = updated_extraction['id']
        else:
            # ìƒˆë¡œìš´ ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥
            logger.info("ìƒˆë¡œìš´ ERP ì¶”ì¶œ ê²°ê³¼ ì €ì¥")
            new_extraction = supabase_mgr.save_erp_extraction(
                session_id=session_id,
                erp_data=erp_data.dict(by_alias=True)
            )
            extraction_id = new_extraction['id']
        
        logger.info(f"ERP ì¬ì¶”ì¶œ ì™„ë£Œ - ì„¸ì…˜ ID: {session_id}, ì¶”ì¶œ ID: {extraction_id}")
        
        return {
            "status": "success",
            "message": "ERP ì¬ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
            "session_id": session_id,
            "extraction_id": extraction_id,
            "erp_data": erp_data
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ERP ì¬ì¶”ì¶œ ì‹¤íŒ¨ - ì„¸ì…˜ ID: {session_id}: {e}")
        raise HTTPException(status_code=500, detail=f"ERP ì¬ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/extractions")
async def get_erp_extractions(
    limit: int = 50, 
    offset: int = 0,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """ERP ì¶”ì¶œ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        extractions = supabase_mgr.get_erp_extractions(limit=limit, offset=offset)
        return {
            "status": "success",
            "extractions": extractions,
            "total": len(extractions)
        }
    except Exception as e:
        logger.error(f"ì¶”ì¶œ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì¶”ì¶œ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/statistics")
async def get_system_statistics(
    date_filter: Optional[str] = None,
    month_filter: Optional[str] = None,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """
    ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ
    
    Args:
        date_filter: YYYY-MM-DD í˜•ì‹ì˜ íŠ¹ì • ë‚ ì§œ í•„í„°
        month_filter: YYYY-MM í˜•ì‹ì˜ ì›”ë³„ í•„í„°
    """
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        # ë‚ ì§œ í•„í„°ë§ íŒŒë¼ë¯¸í„° ê²°ì •
        filter_params = {}
        if date_filter:
            filter_params['date_filter'] = date_filter
        elif month_filter:
            filter_params['month_filter'] = month_filter
        
        stats = supabase_mgr.get_statistics(**filter_params)
        return {
            "status": "success",
            "statistics": stats,
            "applied_filter": {
                "date_filter": date_filter,
                "month_filter": month_filter
            }
        }
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/audio-files")
async def get_audio_files():
    """
    src_record ë””ë ‰í† ë¦¬ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± íŒŒì¼ ëª©ë¡ì„ ì¡°íšŒ
    - ê¸°ì¡´ src_record ì§ì ‘ í•˜ìœ„ íŒŒì¼ë“¤
    - ì¼ìë³„ í´ë”(YYYY-MM-DD) ë‚´ì˜ íŒŒì¼ë“¤
    """
    try:
        if not os.path.exists(AUDIO_DIRECTORY):
            return {
                "status": "error",
                "message": f"ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬({AUDIO_DIRECTORY})ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "files": [],
                "daily_files": {}
            }
        
        # ê¸°ì¡´ src_record ì§ì ‘ í•˜ìœ„ ìŒì„± íŒŒì¼ë“¤ ê²€ìƒ‰
        audio_files = []
        daily_files = {}
        
        for item in os.listdir(AUDIO_DIRECTORY):
            item_path = os.path.join(AUDIO_DIRECTORY, item)
            
            # íŒŒì¼ì¸ ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
            if os.path.isfile(item_path):
                file_extension = os.path.splitext(item)[1].lower()
                if file_extension in SUPPORTED_AUDIO_EXTENSIONS:
                    # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                    file_stat = os.stat(item_path)
                    file_info = {
                        "filename": item,
                        "path": item,  # ê¸°ì¡´ íŒŒì¼ì€ íŒŒì¼ëª…ë§Œ
                        "size": file_stat.st_size,
                        "modified": datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                        "extension": file_extension,
                        "location": "root"  # ë£¨íŠ¸ ë””ë ‰í† ë¦¬ í‘œì‹œ
                    }
                    audio_files.append(file_info)
            
            # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° (ì¼ìë³„ í´ë” í™•ì¸)
            elif os.path.isdir(item_path):
                # YYYY-MM-DD í˜•ì‹ì¸ì§€ í™•ì¸
                try:
                    # ë‚ ì§œ í˜•ì‹ ê²€ì¦
                    datetime.strptime(item, '%Y-%m-%d')
                    
                    # ì¼ìë³„ í´ë” ë‚´ ìŒì„± íŒŒì¼ë“¤ ê²€ìƒ‰
                    daily_audio_files = []
                    for daily_filename in os.listdir(item_path):
                        daily_file_path = os.path.join(item_path, daily_filename)
                        
                        if os.path.isfile(daily_file_path):
                            file_extension = os.path.splitext(daily_filename)[1].lower()
                            if file_extension in SUPPORTED_AUDIO_EXTENSIONS:
                                # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
                                file_stat = os.stat(daily_file_path)
                                file_info = {
                                    "filename": daily_filename,
                                    "path": f"{item}/{daily_filename}",  # ë‚ ì§œí´ë”/íŒŒì¼ëª…
                                    "size": file_stat.st_size,
                                    "modified": datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                                    "extension": file_extension,
                                    "location": item  # ë‚ ì§œ í´ë”ëª…
                                }
                                daily_audio_files.append(file_info)
                    
                    if daily_audio_files:
                        daily_files[item] = daily_audio_files
                        
                except ValueError:
                    # ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹Œ ë””ë ‰í† ë¦¬ëŠ” ë¬´ì‹œ
                    continue
        
        # ì „ì²´ íŒŒì¼ ìˆ˜ ê³„ì‚°
        total_files = len(audio_files) + sum(len(files) for files in daily_files.values())
        
        # íŒŒì¼ëª…ìœ¼ë¡œ ì •ë ¬
        audio_files.sort(key=lambda x: x['filename'])
        for date_folder in daily_files:
            daily_files[date_folder].sort(key=lambda x: x['filename'])
        
        logger.info(f"ë°œê²¬ëœ ìŒì„± íŒŒì¼ ìˆ˜: ë£¨íŠ¸ {len(audio_files)}ê°œ, ì¼ìë³„ {sum(len(files) for files in daily_files.values())}ê°œ (ì´ {total_files}ê°œ)")
        
        return {
            "status": "success",
            "message": f"{total_files}ê°œì˜ ìŒì„± íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.",
            "files": audio_files,  # ê¸°ì¡´ ë£¨íŠ¸ íŒŒì¼ë“¤
            "daily_files": daily_files,  # ì¼ìë³„ í´ë”ì˜ íŒŒì¼ë“¤
            "directory": AUDIO_DIRECTORY,
            "today_folder": datetime.now().strftime('%Y-%m-%d')  # ì˜¤ëŠ˜ ë‚ ì§œ í´ë”ëª…
        }
        
    except Exception as e:
        logger.error(f"ìŒì„± íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "message": f"ìŒì„± íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "files": [],
            "daily_files": {}
        }

@app.get("/api/register-logs")
async def get_register_logs(
    limit: int = 50, 
    offset: int = 0,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """ERP ë“±ë¡ ë¡œê·¸ ëª©ë¡ ì¡°íšŒ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        register_logs = supabase_mgr.get_erp_register_logs(limit=limit, offset=offset)
        return {
            "status": "success",
            "register_logs": register_logs,
            "total": len(register_logs)
        }
    except Exception as e:
        logger.error(f"ë“±ë¡ ë¡œê·¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë“±ë¡ ë¡œê·¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ë””ë ‰í† ë¦¬ë³„ íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ê´€ë ¨ API

@app.get("/api/directory-summary")
async def get_directory_summary(folder: str = None, supabase_mgr=Depends(get_supabase_manager_dep)):
    """ë””ë ‰í† ë¦¬ë³„ ì²˜ë¦¬ í˜„í™© ìš”ì•½ ì¡°íšŒ"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        summary = supabase_mgr.get_directory_processing_summary(folder=folder)
        return {
            "status": "success",
            "summary": summary,
            "total_directories": len(summary),
            "folder_filter": folder
        }
    except Exception as e:
        logger.error(f"ë””ë ‰í† ë¦¬ë³„ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë””ë ‰í† ë¦¬ë³„ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/file-processing-status")
async def get_file_processing_status(
    directory: str = None,
    limit: int = 200,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ (ë””ë ‰í† ë¦¬ë³„ í•„í„°ë§ ì§€ì›)"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        if directory:
            files = supabase_mgr.get_file_processing_status_by_directory(directory=directory, limit=limit)
        else:
            files = supabase_mgr.get_file_processing_status(limit=limit)
        
        return {
            "status": "success",
            "files": files,
            "total": len(files),
            "directory": directory if directory else "ì „ì²´"
        }
    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/check-file-processed")
async def check_file_processed(
    file_path: str,
    supabase_mgr=Depends(get_supabase_manager_dep)
):
    """íŠ¹ì • íŒŒì¼ì˜ ì²˜ë¦¬ ì—¬ë¶€ í™•ì¸"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        result = supabase_mgr.check_file_processed(file_path)
        return {
            "status": "success",
            **result
        }
    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ ({file_path}): {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/processing-summary-enhanced")
async def get_processing_summary_enhanced(supabase_mgr=Depends(get_supabase_manager_dep)):
    """í–¥ìƒëœ ì „ì²´ ì²˜ë¦¬ ìƒíƒœ ìš”ì•½ (ë””ë ‰í† ë¦¬ë³„ í¬í•¨)"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        summary = supabase_mgr.get_processing_summary_enhanced()
        return {
            "status": "success",
            **summary
        }
    except Exception as e:
        logger.error(f"í–¥ìƒëœ ì²˜ë¦¬ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"í–¥ìƒëœ ì²˜ë¦¬ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/update-directory-view")
async def update_directory_view(supabase_mgr=Depends(get_supabase_manager_dep)):
    """ë””ë ‰í† ë¦¬ë³„ ì²˜ë¦¬ í˜„í™© ë·°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤"""
    if not supabase_mgr:
        raise HTTPException(status_code=503, detail="Supabaseê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        success = supabase_mgr.update_directory_view()
        if success:
            return {
                "status": "success",
                "message": "directory_processing_summary ë·°ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"
            }
        else:
            raise HTTPException(status_code=500, detail="ë·° ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"ë·° ì—…ë°ì´íŠ¸ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë·° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")

@app.post("/api/ensure-daily-folder")
async def ensure_daily_folder():
    """
    ìˆ˜ë™ìœ¼ë¡œ ì˜¤ëŠ˜ ë‚ ì§œ í´ë” ìƒì„±
    ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ë³„ê°œë¡œ í•„ìš”ì‹œ ìˆ˜ë™ìœ¼ë¡œ í´ë”ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    try:
        today = datetime.now()
        daily_path = ensure_today_folder_exists()
        
        if daily_path:
            return {
                "success": True,
                "message": "ì¼ë³„ í´ë” ìƒì„± ì™„ë£Œ",
                "path": daily_path,
                "date": today.strftime('%Y-%m-%d'),
                "created_at": today.isoformat()
            }
        else:
            raise HTTPException(status_code=500, detail="í´ë” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
            
    except Exception as e:
        logger.error(f"ìˆ˜ë™ í´ë” ìƒì„± API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í´ë” ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.get("/api/check-daily-folders")
async def check_daily_folders():
    """
    í˜„ì¬ ìƒì„±ëœ ì¼ë³„ í´ë”ë“¤ì˜ ëª©ë¡ì„ í™•ì¸
    """
    try:
        if not os.path.exists(AUDIO_DIRECTORY):
            return {
                "success": True,
                "folders": [],
                "total_count": 0,
                "message": "src_record ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
            }
        
        # YYYY-MM-DD í˜•ì‹ì˜ í´ë”ë“¤ë§Œ í•„í„°ë§
        all_items = os.listdir(AUDIO_DIRECTORY)
        date_folders = []
        
        for item in all_items:
            item_path = os.path.join(AUDIO_DIRECTORY, item)
            if os.path.isdir(item_path):
                # YYYY-MM-DD í˜•ì‹ ê²€ì¦
                try:
                    datetime.strptime(item, '%Y-%m-%d')
                    date_folders.append(item)
                except ValueError:
                    continue  # ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹Œ í´ë”ëŠ” ì œì™¸
        
        date_folders.sort(reverse=True)  # ìµœì‹  ë‚ ì§œë¶€í„° ì •ë ¬
        
        return {
            "success": True,
            "folders": date_folders,
            "total_count": len(date_folders),
            "latest_folder": date_folders[0] if date_folders else None,
            "today_exists": datetime.now().strftime('%Y-%m-%d') in date_folders
        }
        
    except Exception as e:
        logger.error(f"ì¼ë³„ í´ë” í™•ì¸ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í´ë” í™•ì¸ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/environment-status")
async def get_environment_status():
    """í™˜ê²½ë³€ìˆ˜ ì„¤ì • ìƒíƒœ í™•ì¸"""
    env_status = {}
    
    # OpenAI API Key í™•ì¸
    openai_key = os.getenv('OPENAI_API_KEY')
    env_status['OPENAI_API_KEY'] = bool(openai_key and openai_key not in ['your_openai_api_key_here', ''])
    
    # Supabase ì„¤ì • í™•ì¸
    supabase_url = os.getenv('SUPABASE_URL')
    supabase_key = os.getenv('SUPABASE_ANON_KEY')
    env_status['SUPABASE_URL'] = bool(supabase_url and supabase_url not in ['your_supabase_url_here', ''])
    env_status['SUPABASE_ANON_KEY'] = bool(supabase_key and supabase_key not in ['your_supabase_anon_key_here', ''])
    
    # HuggingFace Token í™•ì¸
    hf_token = os.getenv('HUGGINGFACE_HUB_TOKEN')
    env_status['HUGGINGFACE_HUB_TOKEN'] = bool(hf_token and hf_token not in ['your_huggingface_token_here', ''])
    
    return {
        "status": "success",
        "environment_variables": env_status,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/model-status")
async def get_model_status():
    """ëª¨ë¸ ë¡œë”© ìƒíƒœ í™•ì¸"""
    try:
        model_status = {
            "whisper_base_loaded": whisper_model is not None,
            "cached_models": list(cached_whisper_models.keys()),
            "erp_extractor_loaded": erp_extractor is not None,
            "supabase_connected": supabase_manager is not None
        }
        
        # ìºì‹œëœ ëª¨ë¸ë“¤ì˜ ìƒì„¸ ì •ë³´
        model_details = {}
        for model_name, model in cached_whisper_models.items():
            model_details[model_name] = {
                "loaded": model is not None,
                "type": str(type(model).__name__) if model else None
            }
        
        return {
            "status": "success",
            "model_status": model_status,
            "model_details": model_details,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "status": "error",
            "message": f"ëª¨ë¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

@app.post("/api/clear-whisper-cache")
async def clear_whisper_cache():
    """ì†ìƒëœ Whisper ëª¨ë¸ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"""
    try:
        # ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
        clear_model_cache()
        
        # íŒŒì¼ ìºì‹œ ì •ë¦¬
        success, cleared_paths = clear_whisper_file_cache()
        
        if success:
            return {
                "status": "success",
                "message": "Whisper ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "cleared_paths": cleared_paths,
                "action_required": "API ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ê±°ë‚˜ ìƒˆ ëª¨ë¸ì„ ë¡œë”©í•´ì£¼ì„¸ìš”.",
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "status": "warning",
                "message": "ì •ë¦¬í•  ìºì‹œ íŒŒì¼ì´ ì—†ê±°ë‚˜ ì¼ë¶€ ì •ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "cleared_paths": cleared_paths,
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"ìºì‹œ ì •ë¦¬ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/reload-base-model")
async def reload_base_model():
    """Whisper tiny ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë”©í•©ë‹ˆë‹¤ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
    global whisper_model
    
    try:
        logger.info("Whisper tiny ëª¨ë¸ ì¬ë¡œë”© ì‹œì‘... (ë©”ëª¨ë¦¬ ìµœì í™”)")
        
        # ê¸°ì¡´ ëª¨ë¸ ì •ë¦¬
        if whisper_model is not None:
            del whisper_model
        cached_whisper_models.clear()
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        import gc
        gc.collect()
        
        # ìƒˆë¡œ ë¡œë”© (tiny ëª¨ë¸ ê°•ì œ)
        import time
        start_time = time.time()
        whisper_model = whisper.load_model("tiny")
        loading_time = time.time() - start_time
        
        # ìºì‹œì— ì €ì¥
        cached_whisper_models["tiny"] = whisper_model
        
        logger.info(f"Whisper tiny ëª¨ë¸ ì¬ë¡œë”© ì™„ë£Œ (ì†Œìš”ì‹œê°„: {loading_time:.2f}ì´ˆ)")
        
        return {
            "status": "success",
            "message": "Whisper tiny ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì¬ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "loading_time": round(loading_time, 2),
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ì¬ë¡œë”© ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ì¬ë¡œë”© ì‹¤íŒ¨: {str(e)}")

# ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ì´ˆê¸°í™”
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    global scheduler
    logger.info("API ì„œë²„ ì‹œì‘ ì¤‘...")
    
    # FFmpeg ê²½ë¡œ ì„¤ì • (Render/Linux í™˜ê²½ í˜¸í™˜)
    try:
        # Render í™˜ê²½ì—ì„œëŠ” FFmpegê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ Windows íŠ¹ì • ê²½ë¡œ ì„¤ì • ê±´ë„ˆë›°ê¸°
        import platform
        if platform.system() == "Windows":
            # Windows í™˜ê²½ì—ì„œë§Œ íŠ¹ì • ê²½ë¡œ í™•ì¸
            potential_paths = [
                r"C:\Users\bangm\AppData\Local\Microsoft\WinGet\Packages\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\ffmpeg-7.1.1-full_build\bin",
                r"C:\ffmpeg\bin",
                r"C:\Program Files\ffmpeg\bin"
            ]
            
            for ffmpeg_path in potential_paths:
                if os.path.exists(ffmpeg_path):
                    current_path = os.environ.get('PATH', '')
                    if ffmpeg_path not in current_path:
                        os.environ['PATH'] = current_path + os.pathsep + ffmpeg_path
                        logger.info(f"FFmpeg ê²½ë¡œ ì¶”ê°€ë¨: {ffmpeg_path}")
                    else:
                        logger.info("FFmpeg ê²½ë¡œê°€ ì´ë¯¸ PATHì— ìˆìŠµë‹ˆë‹¤.")
                    break
            else:
                logger.info("Windowsì—ì„œ FFmpeg ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        else:
            # Linux/Render í™˜ê²½ì—ì„œëŠ” FFmpegê°€ ì¼ë°˜ì ìœ¼ë¡œ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆìŒ
            logger.info("Linux í™˜ê²½: ì‹œìŠ¤í…œ FFmpeg ì‚¬ìš©")
    except Exception as e:
        logger.warning(f"FFmpeg ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
    
    try:
        # ëª¨ë¸ ì´ˆê¸°í™”
        initialize_models()
        
        # ì¼ìë³„ í´ë” ìƒì„±
        daily_path = create_daily_directory()
        if daily_path:
            logger.info(f"ì¼ìë³„ í´ë” ì„¤ì • ì™„ë£Œ: {daily_path}")
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ì˜¤ë¥˜ê°€ ìˆì–´ë„ API ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰)
        if SCHEDULER_AVAILABLE:
            try:
                scheduler = BackgroundScheduler()
                scheduler.add_job(
                    scheduled_daily_folder_creation,
                    CronTrigger(hour=0, minute=0),  # ë§¤ì¼ 0ì‹œ ì‹¤í–‰
                    id='daily_folder_creation',
                    name='ì¼ë³„ í´ë” ìë™ ìƒì„±'
                )
                scheduler.start()
                logger.info("âœ… ì¼ë³„ í´ë” ìƒì„± ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ (ë§¤ì¼ 0ì‹œ ì‹¤í–‰)")
            except ImportError as e:
                logger.warning(f"âš ï¸ APScheduler íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
                logger.warning("âš ï¸ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install APScheduler>=3.10.0")
            except Exception as e:
                logger.error(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨ (API ì„œë²„ëŠ” ê³„ì† ì‹¤í–‰): {e}")
        else:
            logger.warning("âš ï¸ APSchedulerê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì¼ë³„ í´ë” ìƒì„± ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        
        logger.info("API ì„œë²„ ì‹œì‘ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"API ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    global scheduler
    logger.info("API ì„œë²„ ì¢…ë£Œ ì¤‘...")
    try:
        if SCHEDULER_AVAILABLE and scheduler and scheduler.running:
            scheduler.shutdown(wait=False)
            logger.info("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì™„ë£Œ")
        logger.info("API ì„œë²„ ì¢…ë£Œ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"API ì„œë²„ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    import uvicorn
    
    # ê°œë°œ ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 